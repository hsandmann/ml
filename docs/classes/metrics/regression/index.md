
Regression tasks predict continuous values. The following metrics evaluate the accuracy of predicted values against true values:

| Metric | Purpose | Formula | Use Case |
|--------|---------|:-------:|----------|
| Mean Absolute Error (MAE) | Measures average absolute difference between predictions and true values | \( \displaystyle \frac{1}{N} \sum_{i=1}^N \vert y_i - \hat{y}_i \vert \) | Robust to outliers, interpretable as average error |
| Mean Squared Error (MSE) | Measures average squared difference between predictions and true values | \( \displaystyle \frac{1}{N} \sum_{i=1}^N (y_i - \hat{y}_i)^2 \) | Sensitive to outliers, commonly used in neural network loss functions |
| Root Mean Squared Error (RMSE) | Square root of MSE, providing error in same units as target | \( \displaystyle \sqrt{\frac{1}{N} \sum_{i=1}^N (y_i - \hat{y}_i)^2} \) | Preferred for interpretable error magnitude, widely used in forecasting |
| Mean Absolute Percentage Error (MAPE) | Measures average percentage error relative to true values | \( \displaystyle \frac{1}{N} \sum_{i=1}^N \left \vert \frac{y_i - \hat{y}_i}{y_i} \right \vert \cdot 100 \) | Useful when relative errors matter (e.g., financial predictions), but sensitive to zero or near-zero true values |
| $R^2$ (Coefficient of Determination) | Measures proportion of variance in dependent variable explained by model | \( \displaystyle 1 - \frac{\sum_{i=1}^N (y_i - \hat{y}_i)^2}{\sum_{i=1}^N (y_i - \bar{y})^2} \) | Indicates model fit, with values closer to 1 indicating better fit |
| Adjusted $R^2$ | Adjusts R² for number of predictors, penalizing overly complex models | \( \displaystyle 1 - \left( \frac{(1 - R^2)(N - 1)}{N - k - 1} \right) \) | Useful when comparing models with different numbers of features |
| Median Absolute Error ($\text{MedAE}$) | Measures median of absolute differences, highly robust to outliers | \( \displaystyle \text{median}(\vert y_1 - \hat{y}_1 \vert, \dots, \vert y_N - \hat{y}_N \vert) \) | Preferred in datasets with extreme values or non-Gaussian errors |
<!-- | Huber Loss | Combines MSE and MAE, less sensitive to outliers than MSE | \( \displaystyle L_\delta(y_i, \hat{y}_i) = \begin{cases} \frac{1}{2}(y_i - \hat{y}_i)^2 & \text{if } \|y_i - \hat{y}_i\| \leq \delta \\ \delta \|y_i - \hat{y}_i\| - \frac{1}{2}\delta^2 & \text{otherwise} \end{cases} \) | Used in robust regression tasks, often as a loss function in neural networks |
| Explained Variance Score | Measures proportion of variance explained by the model, similar to R² | \( \displaystyle 1 - \frac{\text{Var}(y - \hat{y})}{\text{Var}(y)} \) | Indicates how well the model captures variability in the data | -->